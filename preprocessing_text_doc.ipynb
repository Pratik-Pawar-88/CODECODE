{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPINiUULbGvHmlaX/Qn8EjG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bbvb3SokkAum","executionInfo":{"status":"ok","timestamp":1699457625498,"user_tz":-330,"elapsed":3158,"user":{"displayName":"Pratik Pawar","userId":"14360487724810830105"}},"outputId":"207f8134-5b0a-4ccb-dc86-5a2e0fcd6578"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}],"source":["import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('averaged_perceptron_tagger')"]},{"cell_type":"code","source":["# Function for Part-of-Speech (POS) tagging\n","def perform_pos_tagging(text):\n","    # Tokenize the input text\n","    words = nltk.word_tokenize(text)\n","    # Perform POS tagging\n","    pos_tags = nltk.pos_tag(words)\n","    return pos_tags"],"metadata":{"id":"6etLZSnFkFNM","executionInfo":{"status":"ok","timestamp":1699457640684,"user_tz":-330,"elapsed":500,"user":{"displayName":"Pratik Pawar","userId":"14360487724810830105"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Function for tokenization\n","def tokenize_text(text):\n","    # Tokenize the input text\n","    words = word_tokenize(text)\n","    return words"],"metadata":{"id":"nV6_fN3UkaGj","executionInfo":{"status":"ok","timestamp":1699457650172,"user_tz":-330,"elapsed":8,"user":{"displayName":"Pratik Pawar","userId":"14360487724810830105"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Function for lemmatization\n","def lemmatize_text(text):\n","    # Tokenize the input text\n","    words = word_tokenize(text)\n","    # Initialize a WordNet Lemmatizer\n","    lemmatizer = WordNetLemmatizer()\n","    # Apply lemmatization to each word\n","    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n","    # Reconstruct the text with lemmatization\n","    result_text = ' '.join(lemmatized_words)\n","    return result_text"],"metadata":{"id":"H-ThSF7Dkcem","executionInfo":{"status":"ok","timestamp":1699457662055,"user_tz":-330,"elapsed":433,"user":{"displayName":"Pratik Pawar","userId":"14360487724810830105"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Function for stop word removal\n","def remove_stopwords(text):\n","    # Tokenize the input text\n","    words = word_tokenize(text)\n","    # Define a list of English stopwords\n","    stop_words = set(stopwords.words('english'))\n","    # Remove stop words\n","    filtered_words = [word for word in words if word.lower() not in stop_words]\n","    # Reconstruct the text without stop words\n","    result_text = ' '.join(filtered_words)\n","    return result_text\n"],"metadata":{"id":"7ETBRvjmkfYu","executionInfo":{"status":"ok","timestamp":1699457672392,"user_tz":-330,"elapsed":5,"user":{"displayName":"Pratik Pawar","userId":"14360487724810830105"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Function for stemming\n","def perform_stemming(text):\n","    # Tokenize the input text\n","    words = word_tokenize(text)\n","    # Initialize a Porter Stemmer\n","    stemmer = PorterStemmer()\n","    # Apply stemming to each word\n","    stemmed_words = [stemmer.stem(word) for word in words]\n","    # Reconstruct the text with stemming\n","    result_text = ' '.join(stemmed_words)\n","    return result_text"],"metadata":{"id":"zmYjHkX6kh8H","executionInfo":{"status":"ok","timestamp":1699457686304,"user_tz":-330,"elapsed":7,"user":{"displayName":"Pratik Pawar","userId":"14360487724810830105"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Input text\n","input_text = \"This is an example of a document for tokenization. This is an example document for POS tagging and stemming.\"\n"],"metadata":{"id":"kVjHrdJ9klWN","executionInfo":{"status":"ok","timestamp":1699457710854,"user_tz":-330,"elapsed":415,"user":{"displayName":"Pratik Pawar","userId":"14360487724810830105"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Apply stop word removal\n","stopword_removed_text = remove_stopwords(input_text)\n"],"metadata":{"id":"mOsbHEkykrTs","executionInfo":{"status":"ok","timestamp":1699457719502,"user_tz":-330,"elapsed":5,"user":{"displayName":"Pratik Pawar","userId":"14360487724810830105"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Apply stemming\n","stemmed_text = perform_stemming(input_text)"],"metadata":{"id":"ovn6Upx1ktZT","executionInfo":{"status":"ok","timestamp":1699457727651,"user_tz":-330,"elapsed":7,"user":{"displayName":"Pratik Pawar","userId":"14360487724810830105"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Tokenize the text\n","tokenized_text = tokenize_text(input_text)"],"metadata":{"id":"RBqf5f20kvjT","executionInfo":{"status":"ok","timestamp":1699457737136,"user_tz":-330,"elapsed":11,"user":{"displayName":"Pratik Pawar","userId":"14360487724810830105"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Lemmatize the text\n","lemmatized_text = lemmatize_text(input_text)\n"],"metadata":{"id":"50H4uw3Mkx3c","executionInfo":{"status":"ok","timestamp":1699457746916,"user_tz":-330,"elapsed":2898,"user":{"displayName":"Pratik Pawar","userId":"14360487724810830105"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Apply POS tagging\n","pos_tags_result = perform_pos_tagging(input_text)"],"metadata":{"id":"wljXGoIxkzcj","executionInfo":{"status":"ok","timestamp":1699457751305,"user_tz":-330,"elapsed":4,"user":{"displayName":"Pratik Pawar","userId":"14360487724810830105"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Display the results\n","print(\"Original Text:\")\n","print(input_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7so9zkSdk1Sr","executionInfo":{"status":"ok","timestamp":1699457761880,"user_tz":-330,"elapsed":9,"user":{"displayName":"Pratik Pawar","userId":"14360487724810830105"}},"outputId":"6dda1345-e60b-45d8-e3dd-7d3045057ba1"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Text:\n","This is an example of a document for tokenization. This is an example document for POS tagging and stemming.\n"]}]},{"cell_type":"code","source":["print(\"After Stopword Removal:\")\n","print(stopword_removed_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ms9EsWMak33S","executionInfo":{"status":"ok","timestamp":1699457775829,"user_tz":-330,"elapsed":8,"user":{"displayName":"Pratik Pawar","userId":"14360487724810830105"}},"outputId":"a979c9a0-a1dc-4ec3-9b02-1e7eeb44d653"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["After Stopword Removal:\n","example document tokenization . example document POS tagging stemming .\n"]}]},{"cell_type":"code","source":["print(\"After Stemming:\")\n","print(stemmed_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x7rD3BP0k7Rm","executionInfo":{"status":"ok","timestamp":1699457794912,"user_tz":-330,"elapsed":8,"user":{"displayName":"Pratik Pawar","userId":"14360487724810830105"}},"outputId":"5a95dc15-8519-4397-dd98-243e67123c38"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["After Stemming:\n","thi is an exampl of a document for token . thi is an exampl document for po tag and stem .\n"]}]},{"cell_type":"code","source":["print(\"Tokenized Text:\")\n","print(tokenized_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4IqOMMkWk_51","executionInfo":{"status":"ok","timestamp":1699457805547,"user_tz":-330,"elapsed":449,"user":{"displayName":"Pratik Pawar","userId":"14360487724810830105"}},"outputId":"e39741d1-d661-42ab-9556-91e6ca2393df"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized Text:\n","['This', 'is', 'an', 'example', 'of', 'a', 'document', 'for', 'tokenization', '.', 'This', 'is', 'an', 'example', 'document', 'for', 'POS', 'tagging', 'and', 'stemming', '.']\n"]}]},{"cell_type":"code","source":["print(\"Lemmatized Text:\")\n","print(lemmatized_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WOjCJyBQlChm","executionInfo":{"status":"ok","timestamp":1699457829517,"user_tz":-330,"elapsed":485,"user":{"displayName":"Pratik Pawar","userId":"14360487724810830105"}},"outputId":"309912cd-d17b-4712-9aca-1ab2b8b94ca1"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Lemmatized Text:\n","This is an example of a document for tokenization . This is an example document for POS tagging and stemming .\n"]}]},{"cell_type":"code","source":["print(\"POS Tagging Results:\")\n","for word, pos_tag in pos_tags_result:\n","    print(f\"{word}: {pos_tag}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vRh2v0rNlEp3","executionInfo":{"status":"ok","timestamp":1699457832600,"user_tz":-330,"elapsed":420,"user":{"displayName":"Pratik Pawar","userId":"14360487724810830105"}},"outputId":"f03255e7-e90a-4a59-bb18-9143d4103f7b"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["POS Tagging Results:\n","This: DT\n","is: VBZ\n","an: DT\n","example: NN\n","of: IN\n","a: DT\n","document: NN\n","for: IN\n","tokenization: NN\n",".: .\n","This: DT\n","is: VBZ\n","an: DT\n","example: NN\n","document: NN\n","for: IN\n","POS: NNP\n","tagging: NN\n","and: CC\n","stemming: NN\n",".: .\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"_AwuVhiIlJIv"},"execution_count":null,"outputs":[]}]}